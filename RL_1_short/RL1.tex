\documentclass[english]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{float}
\usepackage{amsmath}

\makeatletter
\floatstyle{ruled}
\newfloat{algorithm}{tbp}{loa}
\providecommand{\algorithmname}{Algorithm}
\floatname{algorithm}{\protect\algorithmname}
\usepackage{algorithmic}

\makeatother

\usepackage{babel}
\begin{document}

\title{Short Assignment on Bandits}

\author{Ajinkya Ambatwar\\
EE16B104\\
Dept. Of Electrical Engineering}
\maketitle
\begin{abstract}
Here I am attempting to prove the functionality and estimate the ARM
SAMPLE COMPLEXITY of Modified Median Elimination Algorithm for ($\epsilon,\delta)$
- PAC. At every round instead of half of the worst estimated arms,
we are going to eliminate only one-fourth of the worst estimated arms.
\end{abstract}

\section*{Algorithm:}

\begin{algorithm}[H]
\begin{algorithmic}[1]

\STATE Set \textit{S = A}.

\STATE $\epsilon_{1}=\epsilon/4,$ $\delta_{1}=\delta/2,$ $l=1$.

\STATE Sample every arm $a\in S$ for $\frac{2}{\epsilon_{l}^{2}}ln(\frac{7}{3\delta_{l}})$
times, let $Q_{l}(a)$ denote its estimated empirical value

\STATE Find the median of $Q_{l2}(a)$(the lower half of the $Q_{l}(a)$
arranged ascending as per their values), denote it by $m_{l}$.

\STATE $S_{l+1}=S_{l}$\textbackslash{}$\{a:Q_{l}(a)<m_{l}\}$

\STATE If $|S_{l}|=1$, Then output $S_{l}$,

Else $\epsilon_{l+1}=\frac{3}{4}\epsilon_{l};$ $\delta_{l+1}=\delta_{l}/2;$
$l=l+1;$ $n_{l+1}=\frac{3}{4}n_{l}$

\end{algorithmic}

\caption{Modified MEA($\epsilon,\delta)$}
\end{algorithm}

\section*{Theorem:}

\textit{The modified MEA($\epsilon,\delta)$ is an $(\epsilon,\delta)-PAC$
algorithm with arm sample complexity $O(\frac{n}{\epsilon^{2}}ln(\frac{1}{\delta})$}

\subsection*{Lemma 1:}

\textit{For the MEA$(\epsilon,\delta)$ we have that}
\[
Pr[\max_{j\in S_{l}}q_{*}(j)\leq\max_{i\in S_{l+1}}q_{*}(i)+\epsilon_{l}]\geq(1-\delta_{l})
\]

\subsubsection*{Proof: }

Without Loss Of Generality consider $l=1$

$E_{1}=\{Q(a_{l}^{*})<q_{*}(a^{*})-\epsilon/2\}$

Here we are considering the case of underestimating the true value
of the optimal arm in the $l_{th}$ round

So now
\begin{align}
Pr[E_{1}] & =Pr[Q(a_{l}^{*})<q_{*}(a^{*})-\epsilon_{l}/2]\label{Using Chernoff inequality}\\
 & \leq exp(-2\frac{\epsilon_{l}^{2}}{4}n_{l})\\
 & =exp(-2\frac{\epsilon_{l}^{2}}{4}*\frac{2}{\epsilon_{l}^{2}}ln(\frac{7}{3\delta_{l}}))\\
 & =\frac{3\delta_{l}}{7}
\end{align}

Hence $Pr[E_{1}]\leq\frac{3\delta_{l}}{7}$

Now consider the case where we are not underestimating the true value
of the optimal arm but still commiting error by estimating the true
value of some other arm greater than the true value of the optimal
arm. This brings into a CHANCE of the true optimal arm at the $l_{th}$
round getting eliminated.

So the required probability is $Pr[Q_{l}(j)>Q_{l}(a_{l}^{*})|E_{1}^{c}]$.
Let's try to find it out - 

\begin{equation}
P[Q_{l}(j)\geq Q_{l}(a_{l}^{*})|E_{1}^{c}]=P[Q_{l}(j)\geq q_{*}(j)+\epsilon_{l}/2
\end{equation}

So the event of concern will happen only in either of two cases:
\begin{enumerate}
\item We are either underestimating the true value of the optimal arm at
$l_{th}$ round
\item We are overestimating the true value of the suboptimal arm $j$ by
a margin $\epsilon_{l}/2$ 
\end{enumerate}
Given that the scenario 1 does not happen, the equation (5) clearly
imply scenario 2. So now the equation (5) by Chernoff's inequality
turns out to be - 
\begin{align*}
P[Q_{l}(j)\geq q_{*}(j)+\epsilon_{l}/2] & \leq exp(-2\frac{\epsilon^{2}}{4}n_{l})\\
 & \leq\frac{3\delta_{l}}{7}
\end{align*}

Now to possibly eliminate the best arm at the $l_{th}$ round, there
has to be atleast $3S_{l}/4$ ($S_{l}$ is the number of all the non-eliminated
arms in the $l_{th}$round) such $j$ arms. Let us represent the number
of such bad arms by $\#bad$. Hence the expected value of such bad
arms given the event $E_{1}$ does not hold is
\[
E[\#bad|E_{1}^{c}]\leq(|S_{l}|-1)\frac{3\delta_{l}}{7}\leq|S_{l}|\frac{3\delta_{l}}{7}
\]
Now probability of the optimal arm getting eliminated is the probability
that $\#bad\geq3|S_{l}|/4$ 
\begin{align}
P[A_{bad}]=P[\#bad & \geq\frac{3|S_{l}|}{4}|E_{1}^{c}]\leq\frac{E[\#bad|E_{1}^{c}]}{3|S_{l}|/4}\label{Using Markov Inequaity}\\
 & \leq|S_{l}|\frac{3\delta_{l}}{7}*\frac{4}{3|S_{l}|}\\
 & \leq\frac{4\delta_{l}}{7}
\end{align}

Hence for each round probability of commiting error by eliminating
the optimal arm is 
\begin{align*}
P[A_{bad}\bigcup E_{1}] & \leq P[A_{bad}]+P[E_{1}]\\
 & \leq\frac{4\delta_{1}}{7}+\frac{3\delta_{l}}{7}\\
 & \leq\delta_{l}
\end{align*}

Hence the probility of not commiting an error to eliminate the optimal
arm in the $l_{th}$ round is
\begin{equation}
Pr[\max_{j\in S_{l}}q_{*}(j)\leq\max_{i\in S_{l+1}}q_{*}(i)+\epsilon_{l}]
\end{equation}

which means that the optimal arm chosen in $(l+1)_{th}$round is still
$\epsilon-optimal$ to the arm choosen in the $l_{th}$round and the
best arm is not eliminated in the $l_{th}$ round.

The equation (9) is the probability of the event where the optimal
arm is not eliminated in the $l_{th}$ round. Hence the probability
is
\[
Pr[\max_{j\in S_{l}}q_{*}(j)\leq\max_{i\in S_{l+1}}q_{*}(i)+\epsilon_{l}]\geq(1-\delta_{l})
\]

Hence at every $l_{th}$ round the MEA shows that it is an $(\epsilon,\delta)-PAC$
algorithm. Now at every round we are losing atmost $\epsilon_{l}$
from the value of the best optimal arm with the probility of maximum
of $\delta_{l}$. So summing up over all the rounds( $log_{4/3}(n)$,
where $n$ is the total number of arms at the start), $\epsilon_{l}$
accumulates to a suitable $\epsilon$ and the probability will accumulate
to $\delta$ and the last remaining arm at the end of all the rounds
will be the $\epsilon-optimal$ arm for the true best arm such that
-
\[
Pr[q_{*}(a)\geq q_{*}(a^{*})-\epsilon]\geq(1-\delta)
\]

Hence the lemma 1 is proved. Now trying to estimate the arm sample
complexity of the MEA. Noting that each arm $a\in S$ is sampled $\frac{2}{\epsilon_{l}^{2}}ln(\frac{7}{3\delta_{l}})$
times. Hence the number of arm samples in the $l_{th}$ round is $\frac{2n_{l}}{\epsilon_{l}^{2}}ln(\frac{7}{3\delta_{l}})$

Now with each round
\begin{align*}
n_{1} & =n;n_{l}=\frac{3}{4}n_{l-1}=(\frac{3}{4})^{l-1}n
\end{align*}
\[
\epsilon_{1}=\frac{\epsilon}{10};\epsilon_{l}=\frac{9}{10}\epsilon_{l-1}=(\frac{9}{10})^{l-1}\frac{\epsilon}{10}
\]
\[
\delta_{1}=\frac{\delta}{2};\delta_{l}=\frac{\delta_{l-1}}{2}=\frac{\delta}{2^{l}}
\]

The values are chosen such that the infinite summation of $\frac{2n_{l}}{\epsilon_{l}^{2}}ln(\frac{7}{3\delta_{l}})$
over all +ve values of $l$ converges.

Now noting that the rounds end when $n_{l}=1$ which gives $\#l=log_{4/3}(n)$

Therefore we have
\begin{align*}
\sum_{l=1}^{log_{4/3}(n)}\frac{2n_{l}}{\epsilon_{l}^{2}}ln(\frac{7}{3\delta_{l}}) & =2\sum_{l=1}^{log_{4/3}(n)}\frac{n_{l}}{\epsilon_{l}^{2}}ln(\frac{7}{3\delta_{l}})\\
 & =200\sum_{l=1}^{log_{4/3}(n)}(\frac{25}{27})^{l-1}n[\frac{ln(7/3)}{\epsilon^{2}}+l*\frac{ln(2)}{\epsilon^{2}}+\frac{ln(\frac{1}{\delta})}{\epsilon^{2}}]\\
 & \leq\frac{200n}{\epsilon^{2}}ln(\frac{1}{\delta})\sum_{l=1}^{\infty}(\frac{25}{27})^{l-1}[1+\frac{ln(7/3)}{ln(1/\delta)}+l*\frac{ln(2)}{ln(1/\delta)}]\\
 & \leq O(\frac{n}{\epsilon^{2}}ln(\frac{1}{\delta}))
\end{align*}
Hence the arm sample complexity turns out to be of the order $O(\frac{n}{\epsilon^{2}}ln(\frac{1}{\delta}))$
\end{document}
